# No Words for Feelings: Developing Large Language Model Representations of Alexithymia

**Conference:** Canadian Psychological Association Annual National Convention  
**Location:** St. John's, NL  
**Date:** June 12-14, 2025  
**Section:** Quantitative Methods  
**Session ID:** 113656  
**Type:** Poster  

**Main Presenting Author:** Jeremy Barr  
**Additional Authors:** Samantha M. van Rens, Colin T. Henning, Alexander McIntosh, James D.A. Parker  

## Abstract

Alexithymia, characterized by difficulties identifying and describing emotions, presents unique challenges for psychological assessment due to its self-report paradox. Traditional measures like the Toronto Alexithymia Scale (TAS-20) rely on individuals' ability to recognize their emotional processing deficits. This study explores using large language models (LLMs) to develop computational representations of alexithymia through natural language processing. We combined context-free approaches (LIWC, TF-IDF, GloVe) with context-sensitive transformer architectures. Context-free methods provided interpretable baselines, while transformer methods captured nuanced patterns in emotional expression. Model outputs were validated against clinical expert reviews. We fine-tuned DistilBERT through a multi-stage process: 1. a lexical network from validated alexithymia measures; 2. interview transcripts of individuals scoring in the alexithymic and non-alexithymic range on the TAS-20. Transformer approaches showed significant improvements over baselines in identifying alexithymic patterns. Results suggest LLMs can effectively represent alexithymic traits, acting as an objective informant similar to traditional assessments. This approach provides insight into emotional expression without relying on self-reflection capabilities.