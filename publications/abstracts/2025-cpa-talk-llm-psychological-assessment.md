# Fine-Tuning Large Language Models for Psychological Assessment: Lessons from Research on Alexithymia and Emotional Intelligence

**Conference:** Canadian Psychological Association Annual National Convention  
**Location:** St. John's, NL  
**Date:** June 12-14, 2025  
**Section:** Quantitative Methods  
**Session ID:** 112828  
**Type:** 12-Minute Talk  

**Main Presenting Author:** Jeremy Barr  
**Additional Authors:** Samantha M. van Rens, Colin T. Henning, N. Jacob Persi, Alexander McIntosh, James D.A. Parker  

## Abstract

Traditional psychological research is constrained by small sample sizes due to data collection limitations and privacy concerns. Using alexithymia and Emotional Intelligence as test cases, we demonstrate novel approaches to fine-tuning large language models that can help address these fundamental research challenges while maintaining assessment validity. Our methodological approach demonstrates that transformer embeddings enable quantitative analysis of psychological text data through vectorization. We show that NLP-based personality assessment can function similarly to an objective informant, addressing the paradox of self-reporting emotional competencies. By combining open-vocabulary, closed-vocabulary, context-free and context-specific approaches, we enhance model generalizability and validation. The key take-away is that transformer models work best in conjunction with traditional classification approaches. This complementary framework is analogous to using both visual and statistical tests for normality, providing more robust psychological assessment. This talk presents our empirically validated approach to fine-tuning, a framework for combining multiple analytical strategies, and practical solutions for psychological research with constrained sample sizes.
